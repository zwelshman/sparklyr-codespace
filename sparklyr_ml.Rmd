---
  title: "Machine learning modelling with sparklyr"
  output: html_document
---
```{r warning=FALSE, message=FALSE}
library(sparklyr)
library(ggplot2)
library(dplyr)
library(readr)
library(broom)
library(knitr)
library(tidyr)
library(tibble)
library(knitr)
library(broom)
```


```{r warning=FALSE, message=FALSE}
#disconnecting the spark cluster
spark_disconnect_all(sc)

#create spark context
sc <- spark_connect(master = "local", version = "3.2.2")

#To investigate spark jobs/stage etc and for trouble shooting
spark_web(sc)
```

```{r warning=FALSE, message=FALSE}
#reading data from csv and copying into Apache Spark
csv_data <- read_csv('diabetic_data.csv')
spark_data <- copy_to(sc, csv_data, overwrite = TRUE)
```

```{r}
#looking the data 
glimpse(spark_data)
```

```{r warning=FALSE, message=FALSE}
#101766 rows #50 columns
spark_data%>% sdf_dim()

#There are 71518 distinct observations in the patient_nbr column
spark_data%>% 
  sdf_distinct(patient_nbr) %>% 
  sdf_nrow()
```

```{r warning=FALSE, message=FALSE}
#Generating summary statistics on the spark dataframe
spark_data %>% sdf_describe() %>%
  as.data.frame() %>%
  rownames_to_column() %>%
  pivot_longer(cols = -rowname) %>%
  pivot_wider(names_from = rowname) %>%
  rename("Summary" = "name", "Count" = "1", "Mean" = "2", "StDev" = "3", "Min" = "4","Max" = "5") %>%
  filter(Summary != "summary") %>%
  kable()
```

```{r warning=FALSE, message=FALSE}
#do we have duplicate patient ids? Yes
spark_data %>% 
  group_by(patient_nbr) %>%
  filter(n()>1) %>%
  print(n=1000)
```

```{r warning=FALSE, message=FALSE}
#do we have duplicate encounter ids? No
spark_data %>% 
  group_by(encounter_id) %>%
  filter(n()>1) %>%
  print(n=1000)
```

```{r warning=FALSE, message=FALSE}
#Couting rows by readmitted with plot - 
#There is a class imbalance Mostly No then >30, then <30
data_readmitted_group <- spark_data %>%
  group_by(readmitted)  %>%
  summarise(n()) %>%
  collect() %>%
  print()
````

```{r warning=FALSE, message=FALSE}
#Recategorising outcome varaiable to a binary outcome where >30 days = 1 , 
#everything else ==0
spark_data <-spark_data %>%
            #recode outcome variable
            #mutate(less_than_30 = recode(readmitted, "<30" = 1, ">30" = 0, "No" = 0)) %>%
            mutate(less_than_30 = ifelse(readmitted == "<30",1,0)) %>%
            mutate(less_than_30 = as.character(less_than_30))
```


```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(readmitted) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=readmitted, y=Count, x= readmitted)) + 
  geom_bar(posiiton='dodge', stat="identity") +
  theme_minimal()
```

```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(age, gender) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=gender, y=Count, x=age)) + 
  geom_bar(position="dodge", stat="identity") +
  theme_minimal()
```
#Wrangling/visualising
```{r warning=FALSE, message=FALSE}
#Recategorising outcome varaiable to a binary outcome where >30 days = 1 , 
#everything else ==0
spark_data <-spark_data %>%
            #recode outcome variable
            #mutate(less_than_30 = recode(readmitted, "<30" = 1, ">30" = 0, "No" = 0)) %>%
            mutate(less_than_30 = ifelse(readmitted == "<30",1,0)) %>%
            mutate(less_than_30 = as.character(less_than_30))
```
            
```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= less_than_30)) + 
  geom_bar(posiiton='dodge', stat="identity") +
  theme_minimal()
```
  

```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(age, less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill= less_than_30, y=Count, x=age)) + 
  geom_bar(position="dodge", stat="identity") +
   coord_flip()+
  theme_minimal()
```

```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(age, less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill= less_than_30, y=Count, x=age)) + 
  geom_bar(position="fill", stat="identity") +
   coord_flip()+
  theme_minimal()
```

```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(gender, less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= gender)) + 
  geom_bar(position="dodge", stat="identity") +
   coord_flip()+
  theme_minimal()
```

```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(gender, less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= gender)) + 
  geom_bar(position="fill", stat="identity") +
   coord_flip()+
  theme_minimal()
```

```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(race, less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= race)) + 
  geom_bar(position="dodge", stat="identity") +
   coord_flip()+
  theme_minimal()
```

```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(race, less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= race)) + 
  geom_bar(position="fill", stat="identity") +
   coord_flip()+
  theme_minimal()
```

```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(weight, less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= weight)) + 
  geom_bar(position="dodge", stat="identity") +
   coord_flip()+
  theme_minimal()
```

```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(weight, less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= weight)) + 
  geom_bar(position="fill", stat="identity") +
   coord_flip()+
  theme_minimal()
```

```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(admission_type_id , less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= admission_type_id )) + 
  geom_bar(position="dodge", stat="identity") +
   coord_flip()+
  theme_minimal()
```
```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(admission_type_id , less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= admission_type_id )) + 
  geom_bar(position="fill", stat="identity") +
   coord_flip()+
  theme_minimal()
```

```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(time_in_hospital , less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= time_in_hospital )) + 
  geom_bar(position="dodge", stat="identity") +
  theme_minimal()
```

```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(time_in_hospital , less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= time_in_hospital )) + 
  geom_bar(position="fill", stat="identity") +
  theme_minimal()
```


```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(num_medications, less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= num_medications )) + 
  geom_bar(position="dodge", stat="identity") +
  theme_minimal()
```

```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(num_medications, less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= num_medications )) + 
  geom_bar(position="fill", stat="identity") +
  theme_minimal()
```


```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(discharge_disposition_id, less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= discharge_disposition_id )) + 
  geom_bar(position="dodge", stat="identity") +
   coord_flip()+
  theme_minimal()
```

```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(discharge_disposition_id, less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= discharge_disposition_id )) + 
  geom_bar(position="fill", stat="identity") +
   coord_flip()+
  theme_minimal()
```


```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(number_inpatient, less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= number_inpatient )) + 
  geom_histogram(position="dodge", stat="identity") +
  theme_minimal()
```

```{r warning=FALSE, message=FALSE}
#example on plotting counts of the variables
spark_data %>% 
  group_by(number_inpatient, less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= number_inpatient )) + 
  geom_histogram(position="fill", stat="identity") +
  theme_minimal()
```

```{r warning=FALSE, message=FALSE, fig.height = 70, fig.width = 10}
#example on plotting counts of the variables
spark_data %>% 
  group_by(diag_1, less_than_30) %>%
  summarize(Count=n()) %>%
  collect()%>%
  ggplot(aes(fill=less_than_30, y=Count, x= diag_1)) + 
  geom_histogram(position="fill", stat="identity") +
  coord_flip()+
  theme_minimal()
```


```{r warning=FALSE, message=FALSE}
spark_data  <- spark_data %>%
  select(less_than_30, race                    
,gender                  
,age                     
,admission_type_id       
,discharge_disposition_id
,admission_source_id     
,time_in_hospital        
,payer_code              
,medical_specialty       
,num_lab_procedures      
,num_procedures          
,num_medications         
,number_outpatient       
,number_emergency        
,number_inpatient        
,diag_1                  
,diag_2                  
,diag_3                  
,number_diagnoses        
,max_glu_serum           
,A1Cresult               
,metformin               
,repaglinide             
,nateglinide             
,chlorpropamide          
,glimepiride             
,acetohexamide           
,glipizide               
,glyburide               
,tolbutamide             
,pioglitazone            
,rosiglitazone           
,acarbose                
,miglitol                
,troglitazone            
,tolazamide              
,insulin                 
,glimepiridepioglitazone 
,change                  
,diabetesMed)
  
```

```{r warning=FALSE, message=FALSE}
glimpse(spark_data)

```


```{r warning=FALSE, message=FALSE}
# Prepering data for modelling
#basic test train split, could improve this cross validation
split <- sdf_random_split(spark_data, training = 0.70, test = 0.30)

diab_training = split$training
diab_test = split$test
```

```{r warning=FALSE, message=FALSE}
#Getting feature importance by running a model and inspecting selecting top 10
#Logistic Regression
lr_model <- diab_training %>%
  ml_logistic_regression(less_than_30 ~ .)

lr_importances <- tidy(lr_model)
lr_importances%>% arrange(desc(coefficients))
                                             
```

```{r warning=FALSE, message=FALSE}

prepared <- spark_data %>%
  mutate(less_than_30 = as.numeric(less_than_30))%>%
  ft_string_indexer(input_col = "age", output_col = "age_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "race", output_col = "race_indexed", handle_invalid = 'skip')%>%
  ft_string_indexer(input_col = "gender", output_col = "gender_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "admission_type_id", 
                    output_col = "admission_type_id_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "discharge_disposition_id", 
                    output_col = "discharge_disposition_id_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "number_inpatient", 
                    output_col = "number_inpatient_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "diag_1", output_col = "diag_1_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "diabetesMed", output_col = "diabetesMed_indexed", handle_invalid = 'skip') %>%
  
  ft_one_hot_encoder(
    input_cols = c("age_indexed", 
                   "race_indexed", 
                   "gender_indexed",
                   "admission_type_id_indexed",
                   "discharge_disposition_id_indexed",
                   "number_inpatient_indexed",
                   "diag_1_indexed",
                   "diabetesMed_indexed"),
    
    output_cols = c("age_encoded", 
                    "race_encoded", 
                    "gender_encoded",
                    "admission_type_id_encoded",
                    "discharge_disposition_id_encoded",
                    "diag_1_encoded",
                    "number_inpatient_encoded",
                    "diabetesMed_encoded"))

   
glr_model <- ml_generalized_linear_regression(prepared, 
                                              less_than_30 ~ age_encoded +
                                                race_encoded +
                                               time_in_hospital+ 
                                               insulin + A1Cresult +
                                               diabetesMed_encoded,
                                       
                                   family = "binomial")
```

```{r warning=FALSE, message=FALSE,  fig.height = 10, fig.width = 5}

summary(glr_model)

```

```{r warning=FALSE, message=FALSE,  fig.height = 10, fig.width = 5}
#https://therinspark.com/modeling.html#overview-1

tidy_glr <- tidy(glr_model)

tidy_glr%>%
  ggplot(aes(x = term, y = estimate)) +
  geom_point() +
  geom_errorbar(
    aes(ymin = estimate - 1.96 * std.error, 
       ymax = estimate + 1.96 * std.error, width = .1)
  ) +
  coord_flip() +
  geom_hline(yintercept = 0, linetype = "dashed")
```


```{r warning=FALSE, message=FALSE}
#Decision_tree
dt_model <- diab_training %>%
  ml_random_forest_classifier(less_than_30 ~ .)
#importances
dt_importances <- tidy(dt_model)
dt_importances
```

```{r warning=FALSE, message=FALSE}
#gradient_boosted_tree
gbt_model <- diab_training %>%
  ml_gbt_classifier(less_than_30 ~ .)
#importances
gbt_importances <- tidy(gbt_model)
gbt_importances
```


```{r warning=FALSE, message=FALSE}
#logistic regression cross validation with subset of features
pipeline <- ml_pipeline(sc) %>%
  ft_string_indexer(input_col = "age", output_col = "age_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "race", output_col = "race_indexed", handle_invalid = 'skip')%>%
  ft_string_indexer(input_col = "gender", output_col = "gender_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "admission_type_id", 
                    output_col = "admission_type_id_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "discharge_disposition_id", 
                    output_col = "discharge_disposition_id_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "number_inpatient", 
                    output_col = "number_inpatient_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "diag_1", output_col = "diag_1_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "diabetesMed", output_col = "diabetesMed_indexed", handle_invalid = 'skip') %>%
  
  ft_one_hot_encoder(
    input_cols = c("age_indexed", 
                   "race_indexed", 
                   "gender_indexed",
                   "admission_type_id_indexed",
                   "discharge_disposition_id_indexed",
                   "number_inpatient_indexed",
                   "diag_1_indexed",
                   "diabetesMed_indexed"),
    
    output_cols = c("age_encoded", 
                    "race_encoded", 
                    "gender_encoded",
                    "admission_type_id_encoded",
                    "discharge_disposition_id_encoded",
                    "diag_1_encoded",
                    "number_inpatient_encoded",
                    "diabetesMed_encoded")
    
  ) %>%
  ft_vector_assembler(
    input_cols = c("age_encoded", 
                   "race_encoded", 
                   "gender_encoded",
                   "admission_type_id_encoded",
                   "discharge_disposition_id_encoded",
                   "number_inpatient_encoded",
                   "diag_1_encoded",
                   "time_in_hospital",
                   "num_medications",
                   "num_lab_procedures",
                   "number_emergency",
                   "diabetesMed_encoded"),
    
    output_col = "features"
  ) %>%
  
  ft_standard_scaler(input_col = "features", 
                     output_col = "features_scaled", 
                     with_mean = TRUE) %>%
 
  
  ml_logistic_regression(features_col = "features_scaled", 
                         label_col = "less_than_30")

lr_grid <- list(
  logistic_regression = list(
  elastic_net_param = c(0,1),
  reg_param = c(1e-5, 1e-4, 1e-3,1)
  ) 
) 


lr_cv <- ml_cross_validator(
  sc,
  estimator = pipeline,
  estimator_param_maps = lr_grid,
  evaluator = ml_binary_classification_evaluator(sc, 
                                                 label_col = "less_than_30"),
  num_folds = 5)


lr_cv_model <- ml_fit(lr_cv, diab_training%>%
                        mutate(less_than_30 = as.numeric(less_than_30)))

lr_val <- ml_validation_metrics(lr_cv_model) %>%
                arrange(-areaUnderROC)
lr_val

lr_preds_tbl <- ml_predict(lr_cv_model$best_model, diab_test %>%
                        mutate(less_than_30 = as.numeric(less_than_30)))
lr_metrics <- ml_metrics_binary(lr_preds_tbl, truth = "less_than_30")
lr_metrics
```

```{r warning=FALSE, message=FALSE}
#Decsion Trees cross validation with subset of features
pipeline <- ml_pipeline(sc) %>%
  ft_string_indexer(input_col = "age", output_col = "age_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "race", output_col = "race_indexed", handle_invalid = 'skip')%>%
  ft_string_indexer(input_col = "gender", output_col = "gender_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "admission_type_id", 
                    output_col = "admission_type_id_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "discharge_disposition_id", 
                    output_col = "discharge_disposition_id_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "number_inpatient", 
                    output_col = "number_inpatient_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "diag_1", output_col = "diag_1_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "diabetesMed", output_col = "diabetesMed_indexed", handle_invalid = 'skip') %>%
  
  ft_one_hot_encoder(
    input_cols = c("age_indexed", 
                   "race_indexed", 
                   "gender_indexed",
                   "admission_type_id_indexed",
                   "discharge_disposition_id_indexed",
                   "number_inpatient_indexed",
                   "diag_1_indexed",
                   "diabetesMed_indexed"),
    
    output_cols = c("age_encoded", 
                    "race_encoded", 
                    "gender_encoded",
                    "admission_type_id_encoded",
                    "discharge_disposition_id_encoded",
                    "diag_1_encoded",
                    "number_inpatient_encoded",
                    "diabetesMed_encoded")
    
  ) %>%
  ft_vector_assembler(
    input_cols = c("age_encoded", 
                   "race_encoded", 
                   "gender_encoded",
                   "admission_type_id_encoded",
                   "discharge_disposition_id_encoded",
                   "number_inpatient_encoded",
                   "diag_1_encoded",
                   "time_in_hospital",
                   "num_medications",
                   "num_lab_procedures",
                   "number_emergency",
                   "diabetesMed_encoded"),
    
    output_col = "features"
  ) %>%
  
  ft_standard_scaler(input_col = "features", 
                     output_col = "features_scaled", 
                     with_mean = TRUE) %>%
  
  ml_decision_tree_classifier(features_col = "features_scaled", 
                              label_col = 'less_than_30' )

dt_grid <- list( 
  decision_tree = list( 
    max_depth = c(5,10,20), 
    impurity = c("gini",'entropy'),
    max_bins = c(16,32,64),
    min_instances_per_node=c(1,3,5),
    min_info_gain = c(0,1,5)
  ) 
) 

dt_cv <- ml_cross_validator(
  sc,
  estimator = pipeline,
  estimator_param_maps = dt_grid,
  evaluator = ml_binary_classification_evaluator(sc, 
                                                 label_col = "less_than_30"),
  num_folds = 5)

dt_cv_model <- ml_fit(dt_cv, diab_training%>%
                        mutate(less_than_30 = as.numeric(less_than_30)))

dt_val <- ml_validation_metrics(dt_cv_model) %>%
  arrange(-areaUnderROC)
dt_val

dt_preds_tbl <- ml_predict(dt_cv_model$best_model, diab_test%>%
                        mutate(less_than_30 = as.numeric(less_than_30)))
dt_metrics <- ml_metrics_binary(dt_preds_tbl, truth = "less_than_30")
dt_metrics
```


```{r warning=FALSE, message=FALSE}
#Gradient_boosted_trees cross validation with subset of features
pipeline <- ml_pipeline(sc) %>%
  mutate(less_than_30 = as.numeric(less_than_30))%>%
  ft_string_indexer(input_col = "age", output_col = "age_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "race", output_col = "race_indexed", handle_invalid = 'skip')%>%
  ft_string_indexer(input_col = "gender", output_col = "gender_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "admission_type_id", 
                    output_col = "admission_type_id_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "discharge_disposition_id", 
                    output_col = "discharge_disposition_id_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "number_inpatient", 
                    output_col = "number_inpatient_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "diag_1", output_col = "diag_1_indexed", handle_invalid = 'skip') %>%
  ft_string_indexer(input_col = "diabetesMed", output_col = "diabetesMed_indexed", handle_invalid = 'skip') %>%
  
  ft_one_hot_encoder(
    input_cols = c("age_indexed", 
                   "race_indexed", 
                   "gender_indexed",
                   "admission_type_id_indexed",
                   "discharge_disposition_id_indexed",
                   "number_inpatient_indexed",
                   "diag_1_indexed",
                   "diabetesMed_indexed"),
    
    output_cols = c("age_encoded", 
                    "race_encoded", 
                    "gender_encoded",
                    "admission_type_id_encoded",
                    "discharge_disposition_id_encoded",
                    "diag_1_encoded",
                    "number_inpatient_encoded",
                    "diabetesMed_encoded")
    
  ) %>%
  ft_vector_assembler(
    input_cols = c("age_encoded", 
                   "race_encoded", 
                   "gender_encoded",
                   "admission_type_id_encoded",
                   "discharge_disposition_id_encoded",
                   "number_inpatient_encoded",
                   "diag_1_encoded",
                   "time_in_hospital",
                   "num_medications",
                   "num_lab_procedures",
                   "number_emergency",
                   "diabetesMed_encoded"),
    
    output_col = "features"
  ) %>%
  
  ft_standard_scaler(input_col = "features", 
                     output_col = "features_scaled", 
                     with_mean = TRUE) %>%
  
  ml_gbt_classifier(features_col = "features_scaled", 
                    label_col = "less_than_30")

gbt_grid <- list( 
  gbt_classifier = list( 
    loss_type=c("logistic"),
    max_iter = c(20), 
    max_depth = c(1,3,15), 
    max_bins = c(16,32,64),
    step_size = c(0.1,0.01,0.001),
    subsampling_rate=c(1,0.1),
    min_instances_per_node=c(1,3,5),
    feature_subset_strategy = c("sqrt","log2","onethird")
  ) 
) 

gbt_cv <- ml_cross_validator(
  sc,
  estimator = pipeline,
  estimator_param_maps = gbt_grid,
  evaluator = ml_binary_classification_evaluator(sc, 
                                                 label_col = "less_than_30"),
  num_folds = 5)

gbt_cv_model <- ml_fit(gbt_cv, diab_training%>%
                        mutate(less_than_30 = as.numeric(less_than_30)))

gbt_val <- ml_validation_metrics(gbt_cv_model) %>%
               arrange(-areaUnderROC)
gbt_val
gbt_preds_tbl <- ml_predict(gbt_cv_model$best_model, diab_test%>%
                        mutate(less_than_30 = as.numeric(less_than_30)))
gbt_metrics <- ml_metrics_binary(gbt_preds_tbl, truth = "less_than_30")
gbt_metrics 
```

